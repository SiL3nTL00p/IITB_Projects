{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ac0685",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 0: DEVICE SETUP WITH TPU/GPU/CPU FALLBACK\n",
        "# This cell should be run FIRST before any other cells\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def setup_device_strategy():\n",
        "    \"\"\"\n",
        "    Setup device strategy with fallback: TPU -> GPU -> CPU\n",
        "    Returns the strategy to use for training\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DEVICE SETUP\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Try TPU first\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "        print(f\"✓ TPU detected: {tpu.cluster_spec().as_dict()}\")\n",
        "        strategy = tf.distribute.TPUStrategy(tpu)\n",
        "        device_type = \"TPU\"\n",
        "        print(f\"✓ Using TPU strategy with {strategy.num_replicas_in_sync} replicas\")\n",
        "        return strategy, device_type\n",
        "    except (ValueError, tf.errors.NotFoundError):\n",
        "        print(\"✗ No TPU detected\")\n",
        "    \n",
        "    # Try GPU next\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            # Enable memory growth for GPUs to avoid OOM errors\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            \n",
        "            print(f\"✓ GPU(s) detected: {len(gpus)} device(s)\")\n",
        "            for i, gpu in enumerate(gpus):\n",
        "                print(f\"  GPU {i}: {gpu}\")\n",
        "            \n",
        "            if len(gpus) > 1:\n",
        "                # Use MirroredStrategy for multi-GPU\n",
        "                strategy = tf.distribute.MirroredStrategy()\n",
        "                device_type = \"Multi-GPU\"\n",
        "                print(f\"✓ Using MirroredStrategy with {strategy.num_replicas_in_sync} GPUs\")\n",
        "            else:\n",
        "                # Use default strategy for single GPU\n",
        "                strategy = tf.distribute.get_strategy()\n",
        "                device_type = \"Single-GPU\"\n",
        "                print(\"✓ Using single GPU\")\n",
        "            \n",
        "            return strategy, device_type\n",
        "        except RuntimeError as e:\n",
        "            print(f\"✗ GPU setup failed: {e}\")\n",
        "    else:\n",
        "        print(\"✗ No GPU detected\")\n",
        "    \n",
        "    # Fallback to CPU\n",
        "    print(\"✓ Falling back to CPU\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    device_type = \"CPU\"\n",
        "    print(\"⚠ Warning: Training on CPU will be significantly slower\")\n",
        "    \n",
        "    return strategy, device_type\n",
        "\n",
        "# Setup device strategy\n",
        "STRATEGY, DEVICE_TYPE = setup_device_strategy()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"DEVICE CONFIGURATION COMPLETE: {DEVICE_TYPE}\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Number of devices: {STRATEGY.num_replicas_in_sync}\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(\"=\" * 60 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d0f9667",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d0f9667",
        "outputId": "33362c43-6e4f-4bba-8655-6bc210252181"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 1: TRAIN IDENTIFIER MODULE WITH TPU/GPU/CPU SUPPORT\n",
        "# Uses ALL data from single_chromosomes_object folder\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Tuple, Dict\n",
        "import albumentations as A\n",
        "\n",
        "# ==================== SHARED UTILITIES ====================\n",
        "\n",
        "class AnnotationParser:\n",
        "    \"\"\"Parse XML annotations for both single and 24-chromosome datasets\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_xml(xml_path: str) -> Dict:\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        annotations = {\n",
        "            'filename': root.find('filename').text if root.find('filename') is not None else '',\n",
        "            'size': {},\n",
        "            'objects': []\n",
        "        }\n",
        "\n",
        "        size = root.find('size')\n",
        "        if size is not None:\n",
        "            annotations['size'] = {\n",
        "                'width': int(size.find('width').text),\n",
        "                'height': int(size.find('height').text),\n",
        "                'depth': int(size.find('depth').text) if size.find('depth') is not None else 3\n",
        "            }\n",
        "\n",
        "        for obj in root.findall('object'):\n",
        "            name = obj.find('name').text\n",
        "            bndbox = obj.find('bndbox')\n",
        "\n",
        "            if bndbox is not None:\n",
        "                bbox = {\n",
        "                    'xmin': int(float(bndbox.find('xmin').text)),\n",
        "                    'ymin': int(float(bndbox.find('ymin').text)),\n",
        "                    'xmax': int(float(bndbox.find('xmax').text)),\n",
        "                    'ymax': int(float(bndbox.find('ymax').text))\n",
        "                }\n",
        "\n",
        "                annotations['objects'].append({\n",
        "                    'name': name,\n",
        "                    'bbox': bbox\n",
        "                })\n",
        "\n",
        "        return annotations\n",
        "\n",
        "\n",
        "# ==================== IDENTIFIER MODULE ====================\n",
        "\n",
        "class ChromosomeIdentifierDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Data generator for training chromosome identifier\"\"\"\n",
        "\n",
        "    def __init__(self, images_dir: str, annotations_dir: str,\n",
        "                 batch_size=2, img_size=800, shuffle=True):\n",
        "        self.images_dir = images_dir\n",
        "        self.annotations_dir = annotations_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.parser = AnnotationParser()\n",
        "\n",
        "        # Get all image files from directory\n",
        "        self.image_list = []\n",
        "        for filename in os.listdir(images_dir):\n",
        "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                base_name = os.path.splitext(filename)[0]\n",
        "                xml_path = os.path.join(annotations_dir, f\"{base_name}.xml\")\n",
        "                if os.path.exists(xml_path):\n",
        "                    self.image_list.append(base_name)\n",
        "\n",
        "        print(f\"Found {len(self.image_list)} images for identifier training\")\n",
        "\n",
        "        self.indexes = np.arange(len(self.image_list))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_list) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        batch_images = [self.image_list[k] for k in batch_indexes]\n",
        "\n",
        "        X, y = self._generate_data(batch_images)\n",
        "        return X, y\n",
        "\n",
        "    def _generate_data(self, batch_images):\n",
        "        images = []\n",
        "        targets = []\n",
        "\n",
        "        for img_name in batch_images:\n",
        "            img_path = os.path.join(self.images_dir, f\"{img_name}.jpg\")\n",
        "            xml_path = os.path.join(self.annotations_dir, f\"{img_name}.xml\")\n",
        "\n",
        "            if not os.path.exists(img_path):\n",
        "                img_path = os.path.join(self.images_dir, f\"{img_name}.png\")\n",
        "\n",
        "            if not os.path.exists(img_path) or not os.path.exists(xml_path):\n",
        "                continue\n",
        "\n",
        "            image = cv2.imread(img_path)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            orig_h, orig_w = image.shape[:2]\n",
        "\n",
        "            image = cv2.resize(image, (self.img_size, self.img_size))\n",
        "            image = image.astype(np.float32) / 255.0\n",
        "\n",
        "            annotations = self.parser.parse_xml(xml_path)\n",
        "\n",
        "            boxes = []\n",
        "            for obj in annotations['objects']:\n",
        "                bbox = obj['bbox']\n",
        "                xmin = bbox['xmin'] / orig_w\n",
        "                ymin = bbox['ymin'] / orig_h\n",
        "                xmax = bbox['xmax'] / orig_w\n",
        "                ymax = bbox['ymax'] / orig_h\n",
        "                boxes.append([ymin, xmin, ymax, xmax])\n",
        "\n",
        "            images.append(image)\n",
        "            targets.append(np.array(boxes) if len(boxes) > 0 else np.zeros((0, 4)))\n",
        "\n",
        "        return images, targets\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "class ChromosomeIdentifier:\n",
        "    \"\"\"Chromosome detection model\"\"\"\n",
        "\n",
        "    def __init__(self, img_size=800, max_detections=50):\n",
        "        self.img_size = img_size\n",
        "        self.max_detections = max_detections\n",
        "        self.model = None\n",
        "\n",
        "    def _build_model(self):\n",
        "        inputs = layers.Input(shape=(self.img_size, self.img_size, 3))\n",
        "\n",
        "        base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "\n",
        "        for layer in base_model.layers[:100]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        x = base_model.output\n",
        "        x = layers.Conv2D(512, 3, padding='same', activation='relu')(x)\n",
        "        x = layers.Conv2D(512, 3, padding='same', activation='relu')(x)\n",
        "        x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
        "        x = layers.GlobalAveragePooling2D()(x)\n",
        "        x = layers.Dense(1024, activation='relu')(x)\n",
        "        x = layers.Dropout(0.5)(x)\n",
        "\n",
        "        bbox_output = layers.Dense(self.max_detections * 4, name='bbox')(x)\n",
        "        objectness = layers.Dense(self.max_detections, activation='sigmoid', name='objectness')(x)\n",
        "\n",
        "        model = models.Model(inputs=inputs, outputs=[bbox_output, objectness])\n",
        "        return model\n",
        "\n",
        "    def train(self, train_gen, epochs=10, strategy=None):\n",
        "        \"\"\"Train with device strategy support\"\"\"\n",
        "        \n",
        "        # Build model within strategy scope\n",
        "        if strategy is not None:\n",
        "            with strategy.scope():\n",
        "                self.model = self._build_model()\n",
        "                optimizer = optimizers.Adam(0.001)\n",
        "        else:\n",
        "            self.model = self._build_model()\n",
        "            optimizer = optimizers.Adam(0.001)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "            epoch_losses = []\n",
        "\n",
        "            for batch_idx in range(len(train_gen)):\n",
        "                images, targets = train_gen[batch_idx]\n",
        "\n",
        "                if len(images) == 0:\n",
        "                    continue\n",
        "\n",
        "                images = np.array(images)\n",
        "\n",
        "                with tf.GradientTape() as tape:\n",
        "                    bbox_pred, obj_pred = self.model(images, training=True)\n",
        "                    bbox_pred = tf.reshape(bbox_pred, (-1, self.max_detections, 4))\n",
        "\n",
        "                    batch_loss = 0\n",
        "                    for i, target_boxes in enumerate(targets):\n",
        "                        if len(target_boxes) > 0:\n",
        "                            num_objs = min(len(target_boxes), self.max_detections)\n",
        "\n",
        "                            target_padded = np.zeros((self.max_detections, 4))\n",
        "                            target_padded[:num_objs] = target_boxes[:num_objs]\n",
        "\n",
        "                            bbox_loss = tf.reduce_mean(tf.square(bbox_pred[i] - target_padded))\n",
        "\n",
        "                            obj_target = np.zeros(self.max_detections)\n",
        "                            obj_target[:num_objs] = 1\n",
        "                            obj_loss = tf.keras.losses.binary_crossentropy(obj_target, obj_pred[i])\n",
        "\n",
        "                            batch_loss += bbox_loss + 0.5 * tf.reduce_mean(obj_loss)\n",
        "\n",
        "                    batch_loss = batch_loss / len(targets)\n",
        "\n",
        "                grads = tape.gradient(batch_loss, self.model.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "\n",
        "                epoch_losses.append(float(batch_loss))\n",
        "\n",
        "                if (batch_idx + 1) % 10 == 0:\n",
        "                    print(f\"  Batch {batch_idx+1}/{len(train_gen)}, Loss: {np.mean(epoch_losses[-10:]):.4f}\")\n",
        "\n",
        "            print(f\"Epoch Loss: {np.mean(epoch_losses):.4f}\")\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def predict_boxes(self, image, confidence_threshold=0.3):\n",
        "        orig_h, orig_w = image.shape[:2]\n",
        "        image_resized = cv2.resize(image, (self.img_size, self.img_size))\n",
        "        image_resized = image_resized.astype(np.float32) / 255.0\n",
        "        image_resized = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "        bbox_pred, obj_pred = self.model.predict(image_resized, verbose=0)\n",
        "\n",
        "        bbox_pred = bbox_pred.reshape(self.max_detections, 4)\n",
        "        obj_pred = obj_pred.reshape(self.max_detections)\n",
        "\n",
        "        keep = obj_pred > confidence_threshold\n",
        "        boxes = bbox_pred[keep]\n",
        "        scores = obj_pred[keep]\n",
        "\n",
        "        final_boxes = []\n",
        "        for box in boxes:\n",
        "            ymin, xmin, ymax, xmax = box\n",
        "            xmin = int(xmin * orig_w)\n",
        "            ymin = int(ymin * orig_h)\n",
        "            xmax = int(xmax * orig_w)\n",
        "            ymax = int(ymax * orig_h)\n",
        "\n",
        "            xmin = max(0, min(xmin, orig_w))\n",
        "            xmax = max(0, min(xmax, orig_w))\n",
        "            ymin = max(0, min(ymin, orig_h))\n",
        "            ymax = max(0, min(ymax, orig_h))\n",
        "\n",
        "            if xmax > xmin and ymax > ymin:\n",
        "                final_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        return np.array(final_boxes), scores[:len(final_boxes)]\n",
        "\n",
        "\n",
        "# ==================== TRAIN IDENTIFIER ====================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"CELL 1: TRAINING CHROMOSOME IDENTIFIER\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "DATA_ROOT = '/content/drive/MyDrive/ParadoX/inter_iit/2025_Karyogram_CV_Camp'\n",
        "SINGLE_CHR_IMAGES = os.path.join(DATA_ROOT, 'single_chromosomes_object', 'images')\n",
        "SINGLE_CHR_ANNOTATIONS = os.path.join(DATA_ROOT, 'single_chromosomes_object', 'annotations')\n",
        "\n",
        "print(f\"\\nUsing device: {DEVICE_TYPE}\")\n",
        "print(f\"Number of replicas: {STRATEGY.num_replicas_in_sync}\")\n",
        "\n",
        "# Adjust batch size based on device\n",
        "if DEVICE_TYPE == \"TPU\":\n",
        "    BATCH_SIZE = 8 * STRATEGY.num_replicas_in_sync  # TPU works best with larger batches\n",
        "elif DEVICE_TYPE in [\"Single-GPU\", \"Multi-GPU\"]:\n",
        "    BATCH_SIZE = 2 * STRATEGY.num_replicas_in_sync\n",
        "else:  # CPU\n",
        "    BATCH_SIZE = 1  # Smaller batch for CPU\n",
        "\n",
        "print(f\"Adjusted batch size: {BATCH_SIZE}\")\n",
        "\n",
        "train_identifier_gen = ChromosomeIdentifierDataGenerator(\n",
        "    SINGLE_CHR_IMAGES, SINGLE_CHR_ANNOTATIONS,\n",
        "    batch_size=BATCH_SIZE, img_size=800, shuffle=True\n",
        ")\n",
        "\n",
        "identifier = ChromosomeIdentifier(img_size=800, max_detections=50)\n",
        "\n",
        "print(\"\\nStarting identifier training...\")\n",
        "identifier.train(train_identifier_gen, epochs=10, strategy=STRATEGY)\n",
        "\n",
        "identifier.model.save('identifier_model.h5')\n",
        "print(\"\\n✓ Identifier model saved to 'identifier_model.h5'\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "629ab51b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "629ab51b",
        "outputId": "af58ca7e-7a5a-4f83-a3b5-d27c1af96367"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 2: TRAIN CLASSIFIER MODULE WITH TPU/GPU/CPU SUPPORT\n",
        "# Uses ALL data from 24_chromosomes_object folder\n",
        "# ==============================================================================\n",
        "\n",
        "class ChromosomeClassifierDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Data generator for training chromosome classifier\"\"\"\n",
        "\n",
        "    CHROMOSOME_CLASSES = {\n",
        "        '1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5,\n",
        "        '7': 6, '8': 7, '9': 8, '10': 9, '11': 10, '12': 11,\n",
        "        '13': 12, '14': 13, '15': 14, '16': 15, '17': 16, '18': 17,\n",
        "        '19': 18, '20': 19, '21': 20, '22': 21, 'X': 22, 'Y': 23\n",
        "    }\n",
        "\n",
        "    def __init__(self, images_dir: str, annotations_dir: str, is_validation=False,\n",
        "                 batch_size=32, img_size=224, augment=False, validation_split=0.2,\n",
        "                 data=None, indexes=None):\n",
        "        print(f\"\\nInitializing ChromosomeClassifierDataGenerator:\")\n",
        "        self.images_dir = images_dir\n",
        "        self.annotations_dir = annotations_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment\n",
        "        self.validation_split = validation_split\n",
        "        self.is_validation = is_validation\n",
        "        self.parser = AnnotationParser()\n",
        "\n",
        "        # Initialize data storage\n",
        "        if data is None or indexes is None:\n",
        "            self.chromosome_data = []\n",
        "            self._build_dataset()\n",
        "\n",
        "            # Split dataset only for the training generator\n",
        "            if not self.is_validation:\n",
        "                total_samples = len(self.chromosome_data)\n",
        "                val_size = int(total_samples * validation_split)\n",
        "\n",
        "                # Create train/val indexes\n",
        "                np.random.seed(42)\n",
        "                all_indexes = np.arange(total_samples)\n",
        "                np.random.shuffle(all_indexes)\n",
        "\n",
        "                self.indexes = all_indexes[val_size:]\n",
        "                self.val_indexes = all_indexes[:val_size]\n",
        "\n",
        "                print(f\"Train samples: {len(self.indexes)}, Validation samples: {len(self.val_indexes)}\")\n",
        "            else:\n",
        "                self.chromosome_data = data\n",
        "                self.indexes = indexes\n",
        "                self.val_indexes = []\n",
        "                print(f\"Validation samples: {len(self.indexes)}\")\n",
        "        else:\n",
        "            # Use provided data and indexes for validation generator\n",
        "            self.chromosome_data = data\n",
        "            self.indexes = indexes\n",
        "            self.val_indexes = []\n",
        "            print(f\"Validation samples: {len(self.indexes)}\")\n",
        "\n",
        "        # Setup augmentation if required\n",
        "        if augment and not self.is_validation:\n",
        "            self.aug = A.Compose([\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.VerticalFlip(p=0.5),\n",
        "                A.Rotate(limit=15, p=0.5),\n",
        "                A.RandomBrightnessContrast(p=0.3),\n",
        "                A.GaussNoise(p=0.2),\n",
        "            ])\n",
        "        else:\n",
        "            self.aug = None\n",
        "\n",
        "    def _build_dataset(self):\n",
        "        \"\"\"Build dataset from images and annotations\"\"\"\n",
        "        print(\"\\nBuilding classifier dataset...\")\n",
        "\n",
        "        # Get list of valid image files\n",
        "        image_files = []\n",
        "        for filename in os.listdir(self.images_dir):\n",
        "            if filename.endswith(('.jpg', '.png')):\n",
        "                base_name = os.path.splitext(filename)[0]\n",
        "                xml_path = os.path.join(self.annotations_dir, f\"{base_name}.xml\")\n",
        "                if os.path.exists(xml_path):\n",
        "                    image_files.append(base_name)\n",
        "\n",
        "        print(f\"Found {len(image_files)} images to process...\")\n",
        "\n",
        "        # Process each image and its annotations\n",
        "        for img_name in image_files:\n",
        "            img_path = os.path.join(self.images_dir, f\"{img_name}.jpg\")\n",
        "            xml_path = os.path.join(self.annotations_dir, f\"{img_name}.xml\")\n",
        "\n",
        "            # Try PNG if JPG doesn't exist\n",
        "            if not os.path.exists(img_path):\n",
        "                img_path = os.path.join(self.images_dir, f\"{img_name}.png\")\n",
        "\n",
        "            if not os.path.exists(img_path) or not os.path.exists(xml_path):\n",
        "                print(f\"Warning: Missing files for {img_name}\")\n",
        "                continue\n",
        "\n",
        "            # Load and process image\n",
        "            image = cv2.imread(img_path)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Parse annotations\n",
        "            annotations = self.parser.parse_xml(xml_path)\n",
        "\n",
        "            # Extract individual chromosomes\n",
        "            for obj in annotations['objects']:\n",
        "                bbox = obj['bbox']\n",
        "                label = obj['name']\n",
        "\n",
        "                if label in self.CHROMOSOME_CLASSES:\n",
        "                    chromosome_img = image[bbox['ymin']:bbox['ymax'],\n",
        "                                        bbox['xmin']:bbox['xmax']]\n",
        "\n",
        "                    if chromosome_img.size > 0:\n",
        "                        self.chromosome_data.append({\n",
        "                            'image': chromosome_img,\n",
        "                            'label': self.CHROMOSOME_CLASSES[label]\n",
        "                        })\n",
        "\n",
        "        print(f\"Built dataset with {len(self.chromosome_data)} chromosome samples\")\n",
        "\n",
        "    def get_validation_generator(self):\n",
        "        \"\"\"Create validation generator using validation split\"\"\"\n",
        "        val_gen = ChromosomeClassifierDataGenerator(\n",
        "            images_dir=self.images_dir,\n",
        "            annotations_dir=self.annotations_dir,\n",
        "            batch_size=self.batch_size,\n",
        "            img_size=self.img_size,\n",
        "            augment=False,\n",
        "            validation_split=0.0,\n",
        "            is_validation=True,\n",
        "            data=[self.chromosome_data[i] for i in self.val_indexes],\n",
        "            indexes=np.arange(len(self.val_indexes))\n",
        "        )\n",
        "        return val_gen\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return number of batches per epoch\"\"\"\n",
        "        return int(np.ceil(len(self.indexes) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Get batch of data\"\"\"\n",
        "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for idx in batch_indexes:\n",
        "            data = self.chromosome_data[idx]\n",
        "            image = data['image'].copy()\n",
        "            label = data['label']\n",
        "\n",
        "            # Apply augmentation if enabled\n",
        "            if self.aug is not None:\n",
        "                augmented = self.aug(image=image)\n",
        "                image = augmented['image']\n",
        "\n",
        "            # Preprocess image\n",
        "            image = cv2.resize(image, (self.img_size, self.img_size))\n",
        "            image = image.astype(np.float32) / 255.0\n",
        "\n",
        "            # Normalize using ImageNet stats\n",
        "            mean = np.array([0.485, 0.456, 0.406])\n",
        "            std = np.array([0.229, 0.224, 0.225])\n",
        "            image = (image - mean) / std\n",
        "\n",
        "            batch_images.append(image)\n",
        "            batch_labels.append(label)\n",
        "\n",
        "        return np.array(batch_images), np.array(batch_labels)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Called at the end of every epoch\"\"\"\n",
        "        if not self.is_validation:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "class ChromosomeClassifier:\n",
        "    \"\"\"Chromosome classification model (24 classes)\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=24, img_size=224):\n",
        "        self.num_classes = num_classes\n",
        "        self.img_size = img_size\n",
        "        self.model = None\n",
        "\n",
        "    def _build_model(self):\n",
        "        base_model = ResNet50(include_top=False, weights='imagenet',\n",
        "                             input_shape=(self.img_size, self.img_size, 3))\n",
        "\n",
        "        for layer in base_model.layers[:140]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        x = base_model.output\n",
        "        x = layers.GlobalAveragePooling2D()(x)\n",
        "        x = layers.Dense(512, activation='relu')(x)\n",
        "        x = layers.Dropout(0.5)(x)\n",
        "        x = layers.Dense(256, activation='relu')(x)\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
        "\n",
        "        model = models.Model(inputs=base_model.input, outputs=outputs)\n",
        "        return model\n",
        "\n",
        "    def compile_model(self, lr=0.001, strategy=None):\n",
        "        \"\"\"Compile model within strategy scope if provided\"\"\"\n",
        "        if strategy is not None:\n",
        "            with strategy.scope():\n",
        "                self.model = self._build_model()\n",
        "                self.model.compile(\n",
        "                    optimizer=optimizers.Adam(lr),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy']\n",
        "                )\n",
        "        else:\n",
        "            self.model = self._build_model()\n",
        "            self.model.compile(\n",
        "                optimizer=optimizers.Adam(lr),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy']\n",
        "            )\n",
        "\n",
        "    def train(self, train_gen, val_gen, epochs=30):\n",
        "        callbacks = [\n",
        "            keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_accuracy', factor=0.5, patience=3,\n",
        "                min_lr=1e-7, verbose=1\n",
        "            ),\n",
        "            keras.callbacks.ModelCheckpoint(\n",
        "                'best_classifier.h5', monitor='val_accuracy',\n",
        "                save_best_only=True, verbose=1\n",
        "            ),\n",
        "            keras.callbacks.EarlyStopping(\n",
        "                monitor='val_accuracy', patience=7,\n",
        "                restore_best_weights=True, verbose=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        history = self.model.fit(\n",
        "            train_gen,\n",
        "            validation_data=val_gen,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return history\n",
        "\n",
        "\n",
        "# ==================== TRAIN CLASSIFIER ====================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CELL 2: TRAINING CHROMOSOME CLASSIFIER\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "DATA_ROOT = '/content/drive/MyDrive/ParadoX/inter_iit/2025_Karyogram_CV_Camp'\n",
        "MULTI_CHR_IMAGES = os.path.join(DATA_ROOT, '24_chromosomes_object', 'images')\n",
        "MULTI_CHR_ANNOTATIONS = os.path.join(DATA_ROOT, '24_chromosomes_object', 'annotations')\n",
        "\n",
        "print(f\"\\nUsing device: {DEVICE_TYPE}\")\n",
        "print(f\"Number of replicas: {STRATEGY.num_replicas_in_sync}\")\n",
        "\n",
        "# Adjust batch size based on device\n",
        "if DEVICE_TYPE == \"TPU\":\n",
        "    CLASSIFIER_BATCH_SIZE = 128 * STRATEGY.num_replicas_in_sync\n",
        "elif DEVICE_TYPE in [\"Single-GPU\", \"Multi-GPU\"]:\n",
        "    CLASSIFIER_BATCH_SIZE = 32 * STRATEGY.num_replicas_in_sync\n",
        "else:  # CPU\n",
        "    CLASSIFIER_BATCH_SIZE = 8\n",
        "\n",
        "print(f\"Adjusted batch size: {CLASSIFIER_BATCH_SIZE}\")\n",
        "\n",
        "train_classifier_gen = ChromosomeClassifierDataGenerator(\n",
        "    MULTI_CHR_IMAGES, MULTI_CHR_ANNOTATIONS,\n",
        "    batch_size=CLASSIFIER_BATCH_SIZE, img_size=224, augment=True, validation_split=0.2\n",
        ")\n",
        "\n",
        "val_classifier_gen = train_classifier_gen.get_validation_generator()\n",
        "\n",
        "classifier = ChromosomeClassifier(num_classes=24)\n",
        "classifier.compile_model(lr=0.001, strategy=STRATEGY)\n",
        "\n",
        "print(\"\\nStarting classifier training...\")\n",
        "history = classifier.train(train_classifier_gen, val_classifier_gen, epochs=30)\n",
        "\n",
        "print(\"\\n✓ Classifier model saved to 'best_classifier.h5'\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8148cd6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "8148cd6d",
        "outputId": "b9c76346-f6dd-4f8f-a56e-45fa7e059c3f"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 3: INTEGRATION AND EVALUATION WITH DEVICE SUPPORT\n",
        "# Uses train.txt and test.txt to select specific images from 24_chromosomes_object\n",
        "# ==============================================================================\n",
        "\n",
        "class KaryotypePipeline:\n",
        "    \"\"\"End-to-end pipeline integrating identifier and classifier\"\"\"\n",
        "\n",
        "    def __init__(self, identifier: ChromosomeIdentifier,\n",
        "                 classifier: ChromosomeClassifier):\n",
        "        self.identifier = identifier\n",
        "        self.classifier = classifier\n",
        "        self.img_size = 224\n",
        "\n",
        "    def process_image(self, image_path: str, confidence_threshold=0.3):\n",
        "        image = cv2.imread(image_path)\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        boxes, scores = self.identifier.predict_boxes(image_rgb, confidence_threshold=confidence_threshold)\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            return []\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for i, box in enumerate(boxes):\n",
        "            xmin, ymin, xmax, ymax = map(int, box)\n",
        "\n",
        "            chromosome_img = image_rgb[ymin:ymax, xmin:xmax]\n",
        "\n",
        "            if chromosome_img.size == 0:\n",
        "                continue\n",
        "\n",
        "            chromosome_img = cv2.resize(chromosome_img, (self.img_size, self.img_size))\n",
        "            chromosome_img = chromosome_img.astype(np.float32) / 255.0\n",
        "\n",
        "            mean = np.array([0.485, 0.456, 0.406])\n",
        "            std = np.array([0.229, 0.224, 0.225])\n",
        "            chromosome_img = (chromosome_img - mean) / std\n",
        "\n",
        "            chromosome_img = np.expand_dims(chromosome_img, axis=0)\n",
        "\n",
        "            probs = self.classifier.model.predict(chromosome_img, verbose=0)[0]\n",
        "            class_id = np.argmax(probs)\n",
        "            confidence = probs[class_id]\n",
        "\n",
        "            predictions.append({\n",
        "                'bbox': box,\n",
        "                'class_id': int(class_id),\n",
        "                'class_name': self._get_class_name(class_id),\n",
        "                'confidence': float(confidence),\n",
        "                'score': float(scores[i]) if i < len(scores) else 1.0\n",
        "            })\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_class_name(class_id: int) -> str:\n",
        "        if class_id < 22:\n",
        "            return str(class_id + 1)\n",
        "        elif class_id == 22:\n",
        "            return 'X'\n",
        "        else:\n",
        "            return 'Y'\n",
        "\n",
        "\n",
        "def evaluate_pipeline(pipeline: KaryotypePipeline, images_dir: str,\n",
        "                     annotations_dir: str, test_list: List[str],\n",
        "                     output_dir='results'):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    parser = AnnotationParser()\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_probs = []\n",
        "\n",
        "    print(\"Evaluating pipeline on test set...\")\n",
        "    for idx, img_name in enumerate(test_list):\n",
        "        img_name = img_name.strip()\n",
        "        img_path = os.path.join(images_dir, f\"{img_name}.jpg\")\n",
        "        xml_path = os.path.join(annotations_dir, f\"{img_name}.xml\")\n",
        "\n",
        "        if not os.path.exists(img_path):\n",
        "            img_path = os.path.join(images_dir, f\"{img_name}.png\")\n",
        "\n",
        "        if not os.path.exists(img_path) or not os.path.exists(xml_path):\n",
        "            continue\n",
        "\n",
        "        if (idx + 1) % 10 == 0:\n",
        "            print(f\"Processed {idx+1}/{len(test_list)} images...\")\n",
        "\n",
        "        annotations = parser.parse_xml(xml_path)\n",
        "        gt_chromosomes = [obj['name'] for obj in annotations['objects']]\n",
        "\n",
        "        predictions = pipeline.process_image(img_path)\n",
        "\n",
        "        for gt_chr in gt_chromosomes:\n",
        "            if gt_chr in ChromosomeClassifierDataGenerator.CHROMOSOME_CLASSES:\n",
        "                gt_class = ChromosomeClassifierDataGenerator.CHROMOSOME_CLASSES[gt_chr]\n",
        "\n",
        "                true_labels = np.zeros(24)\n",
        "                true_labels[gt_class] = 1\n",
        "\n",
        "                pred_probs = np.zeros(24)\n",
        "                for pred in predictions:\n",
        "                    pred_probs[pred['class_id']] = max(\n",
        "                        pred_probs[pred['class_id']],\n",
        "                        pred['confidence']\n",
        "                    )\n",
        "\n",
        "                all_true_labels.append(true_labels)\n",
        "                all_pred_probs.append(pred_probs)\n",
        "\n",
        "    all_true_labels = np.array(all_true_labels)\n",
        "    all_pred_probs = np.array(all_pred_probs)\n",
        "\n",
        "    auprc_scores = []\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i in range(24):\n",
        "        if np.sum(all_true_labels[:, i]) > 0:\n",
        "            precision, recall, _ = precision_recall_curve(\n",
        "                all_true_labels[:, i],\n",
        "                all_pred_probs[:, i]\n",
        "            )\n",
        "            auprc = auc(recall, precision)\n",
        "            auprc_scores.append(auprc)\n",
        "\n",
        "            plt.plot(recall, precision,\n",
        "                    label=f'Class {pipeline._get_class_name(i)} (auPRC={auprc:.3f})')\n",
        "\n",
        "    plt.xlabel('Recall', fontsize=12)\n",
        "    plt.ylabel('Precision', fontsize=12)\n",
        "    plt.title('Precision-Recall Curves for All Chromosome Classes', fontsize=14)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'auprc_curves.png'),\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    mean_auprc = np.mean(auprc_scores)\n",
        "    print(f\"\\nMean auPRC: {mean_auprc:.4f}\")\n",
        "\n",
        "    with open(os.path.join(output_dir, 'auprc_scores.txt'), 'w') as f:\n",
        "        f.write(f\"Mean auPRC: {mean_auprc:.4f}\\n\\n\")\n",
        "        f.write(\"Per-class auPRC scores:\\n\")\n",
        "        for i, score in enumerate(auprc_scores):\n",
        "            f.write(f\"Class {pipeline._get_class_name(i)}: {score:.4f}\\n\")\n",
        "\n",
        "    return mean_auprc, auprc_scores\n",
        "\n",
        "\n",
        "# ==================== INTEGRATION AND EVALUATION ====================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CELL 3: INTEGRATION AND EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load train/test splits from txt files\n",
        "print(\"\\nLoading train/test splits...\")\n",
        "with open(os.path.join(DATA_ROOT, 'train.txt'), 'r') as f:\n",
        "    train_list = f.readlines()\n",
        "\n",
        "with open(os.path.join(DATA_ROOT, 'test.txt'), 'r') as f:\n",
        "    test_list = f.readlines()\n",
        "\n",
        "print(f\"Train samples from train.txt: {len(train_list)}\")\n",
        "print(f\"Test samples from test.txt: {len(test_list)}\")\n",
        "\n",
        "# Load trained models (within strategy scope if using TPU)\n",
        "print(\"\\nLoading trained models...\")\n",
        "print(f\"Loading on device: {DEVICE_TYPE}\")\n",
        "\n",
        "if DEVICE_TYPE == \"TPU\":\n",
        "    # For TPU, load models within strategy scope\n",
        "    with STRATEGY.scope():\n",
        "        identifier_loaded = ChromosomeIdentifier(img_size=800, max_detections=50)\n",
        "        identifier_loaded.model = keras.models.load_model('identifier_model.h5')\n",
        "        print(\"✓ Identifier model loaded\")\n",
        "\n",
        "        classifier_loaded = ChromosomeClassifier(num_classes=24)\n",
        "        classifier_loaded.model = keras.models.load_model('best_classifier.h5')\n",
        "        print(\"✓ Classifier model loaded\")\n",
        "else:\n",
        "    # For GPU/CPU, load normally\n",
        "    identifier_loaded = ChromosomeIdentifier(img_size=800, max_detections=50)\n",
        "    identifier_loaded.model = keras.models.load_model('identifier_model.h5')\n",
        "    print(\"✓ Identifier model loaded\")\n",
        "\n",
        "    classifier_loaded = ChromosomeClassifier(num_classes=24)\n",
        "    classifier_loaded.model = keras.models.load_model('best_classifier.h5')\n",
        "    print(\"✓ Classifier model loaded\")\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = KaryotypePipeline(identifier_loaded, classifier_loaded)\n",
        "print(\"\\n✓ Pipeline created successfully\")\n",
        "\n",
        "# Evaluate on test set (using images specified in test.txt)\n",
        "print(\"\\nEvaluating pipeline on test set from test.txt...\")\n",
        "mean_auprc, class_auprcs = evaluate_pipeline(\n",
        "    pipeline, MULTI_CHR_IMAGES, MULTI_CHR_ANNOTATIONS,\n",
        "    test_list, output_dir='results'\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Mean auPRC: {mean_auprc:.4f}\")\n",
        "print(f\"\\nResults saved to 'results/' directory:\")\n",
        "print(f\"  - auPRC curve: results/auprc_curves.png\")\n",
        "print(f\"  - Detailed scores: results/auprc_scores.txt\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6baa0f96",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 4: COMPREHENSIVE EVALUATION METRICS WITH DEVICE SUPPORT\n",
        "# Includes Confusion Matrix, ROC Curves, and Detailed Metrics\n",
        "# ==============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, \n",
        "    roc_curve, roc_auc_score, auc,\n",
        "    precision_recall_fscore_support,\n",
        "    accuracy_score, balanced_accuracy_score\n",
        ")\n",
        "import pandas as pd\n",
        "from itertools import cycle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def compute_comprehensive_metrics(pipeline, images_dir, annotations_dir, \n",
        "                                  test_list, output_dir='evaluation_results'):\n",
        "    \"\"\"\n",
        "    Compute comprehensive evaluation metrics including:\n",
        "    - Confusion Matrix\n",
        "    - ROC Curves (One-vs-Rest)\n",
        "    - Classification Report\n",
        "    - Per-class metrics\n",
        "    \"\"\"\n",
        "    \n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    parser = AnnotationParser()\n",
        "    \n",
        "    # Storage for predictions and ground truth\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "    all_pred_probs = []\n",
        "    \n",
        "    # Class mapping\n",
        "    CLASS_NAMES = [str(i+1) for i in range(22)] + ['X', 'Y']\n",
        "    \n",
        "    print(\"Computing comprehensive metrics...\")\n",
        "    print(f\"Processing {len(test_list)} test images...\")\n",
        "    print(f\"Using device: {DEVICE_TYPE}\")\n",
        "    \n",
        "    # Process all test images\n",
        "    for idx, img_name in enumerate(test_list):\n",
        "        img_name = img_name.strip()\n",
        "        img_path = os.path.join(images_dir, f\"{img_name}.jpg\")\n",
        "        xml_path = os.path.join(annotations_dir, f\"{img_name}.xml\")\n",
        "        \n",
        "        if not os.path.exists(img_path):\n",
        "            img_path = os.path.join(images_dir, f\"{img_name}.png\")\n",
        "        \n",
        "        if not os.path.exists(img_path) or not os.path.exists(xml_path):\n",
        "            continue\n",
        "        \n",
        "        if (idx + 1) % 20 == 0:\n",
        "            print(f\"  Processed {idx+1}/{len(test_list)} images...\")\n",
        "        \n",
        "        # Get ground truth\n",
        "        annotations = parser.parse_xml(xml_path)\n",
        "        \n",
        "        # Get predictions\n",
        "        predictions = pipeline.process_image(img_path, confidence_threshold=0.3)\n",
        "        \n",
        "        # Match predictions to ground truth\n",
        "        for obj in annotations['objects']:\n",
        "            gt_chr = obj['name']\n",
        "            if gt_chr not in ChromosomeClassifierDataGenerator.CHROMOSOME_CLASSES:\n",
        "                continue\n",
        "            \n",
        "            gt_class = ChromosomeClassifierDataGenerator.CHROMOSOME_CLASSES[gt_chr]\n",
        "            \n",
        "            # Find best matching prediction (highest confidence)\n",
        "            if predictions:\n",
        "                best_pred = max(predictions, key=lambda x: x['confidence'])\n",
        "                pred_class = best_pred['class_id']\n",
        "                \n",
        "                # Store probabilities for this prediction\n",
        "                pred_probs = np.zeros(24)\n",
        "                pred_probs[pred_class] = best_pred['confidence']\n",
        "            else:\n",
        "                pred_class = 0  # Default to class 0 if no detection\n",
        "                pred_probs = np.zeros(24)\n",
        "                pred_probs[0] = 1.0\n",
        "            \n",
        "            all_true_labels.append(gt_class)\n",
        "            all_pred_labels.append(pred_class)\n",
        "            all_pred_probs.append(pred_probs)\n",
        "    \n",
        "    all_true_labels = np.array(all_true_labels)\n",
        "    all_pred_labels = np.array(all_pred_labels)\n",
        "    all_pred_probs = np.array(all_pred_probs)\n",
        "    \n",
        "    print(f\"\\nTotal samples evaluated: {len(all_true_labels)}\")\n",
        "    \n",
        "    # ==================== CONFUSION MATRIX ====================\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GENERATING CONFUSION MATRIX\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "    \n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(20, 18))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
        "                cbar_kws={'label': 'Count'})\n",
        "    plt.xlabel('Predicted Class', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('True Class', fontsize=14, fontweight='bold')\n",
        "    plt.title('Confusion Matrix - Chromosome Classification', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'), \n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    # Normalized confusion matrix\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    plt.figure(figsize=(20, 18))\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
        "                xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
        "                cbar_kws={'label': 'Proportion'})\n",
        "    plt.xlabel('Predicted Class', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('True Class', fontsize=14, fontweight='bold')\n",
        "    plt.title('Normalized Confusion Matrix - Chromosome Classification', \n",
        "              fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'confusion_matrix_normalized.png'),\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    print(\"✓ Confusion matrices saved\")\n",
        "    \n",
        "    # ==================== ROC CURVES ====================\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GENERATING ROC CURVES\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Convert to binary format for ROC (One-vs-Rest)\n",
        "    from sklearn.preprocessing import label_binarize\n",
        "    y_true_bin = label_binarize(all_true_labels, classes=range(24))\n",
        "    \n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    \n",
        "    for i in range(24):\n",
        "        if np.sum(y_true_bin[:, i]) > 0:  # Only compute if class exists\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], all_pred_probs[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    \n",
        "    # Plot ROC curves\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    colors = cycle(plt.cm.tab20.colors)\n",
        "    \n",
        "    for i, color in zip(range(24), colors):\n",
        "        if i in roc_auc:\n",
        "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "                    label=f'Class {CLASS_NAMES[i]} (AUC = {roc_auc[i]:.3f})')\n",
        "    \n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('True Positive Rate', fontsize=14, fontweight='bold')\n",
        "    plt.title('ROC Curves - One-vs-Rest (All Classes)', fontsize=16, fontweight='bold')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'roc_curves_all.png'),\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    # Compute micro-average and macro-average ROC\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_true_bin.ravel(), all_pred_probs.ravel())\n",
        "    roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    \n",
        "    # Compute macro-average\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in roc_auc.keys()]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in roc_auc.keys():\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "    mean_tpr /= len(roc_auc)\n",
        "    roc_auc_macro = auc(all_fpr, mean_tpr)\n",
        "    \n",
        "    # Plot aggregate ROC curves\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(fpr_micro, tpr_micro, 'b-', lw=3,\n",
        "             label=f'Micro-average (AUC = {roc_auc_micro:.3f})')\n",
        "    plt.plot(all_fpr, mean_tpr, 'r-', lw=3,\n",
        "             label=f'Macro-average (AUC = {roc_auc_macro:.3f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('True Positive Rate', fontsize=14, fontweight='bold')\n",
        "    plt.title('Aggregate ROC Curves', fontsize=16, fontweight='bold')\n",
        "    plt.legend(loc='lower right', fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'roc_curves_aggregate.png'),\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    print(\"✓ ROC curves saved\")\n",
        "    \n",
        "    # ==================== CLASSIFICATION REPORT ====================\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GENERATING CLASSIFICATION REPORT\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Generate classification report\n",
        "    report = classification_report(all_true_labels, all_pred_labels, \n",
        "                                   target_names=CLASS_NAMES, \n",
        "                                   output_dict=True, zero_division=0)\n",
        "    \n",
        "    # Convert to DataFrame for better visualization\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    \n",
        "    # Save detailed report\n",
        "    with open(os.path.join(output_dir, 'classification_report.txt'), 'w') as f:\n",
        "        f.write(\"=\"*80 + \"\\n\")\n",
        "        f.write(\"COMPREHENSIVE CLASSIFICATION REPORT\\n\")\n",
        "        f.write(\"=\"*80 + \"\\n\\n\")\n",
        "        f.write(classification_report(all_true_labels, all_pred_labels,\n",
        "                                     target_names=CLASS_NAMES, zero_division=0))\n",
        "        f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "    \n",
        "    # Save as CSV\n",
        "    report_df.to_csv(os.path.join(output_dir, 'classification_report.csv'))\n",
        "    \n",
        "    print(\"✓ Classification report saved\")\n",
        "    \n",
        "    # ==================== PER-CLASS METRICS ====================\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"COMPUTING PER-CLASS METRICS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        all_true_labels, all_pred_labels, average=None, zero_division=0\n",
        "    )\n",
        "    \n",
        "    # Create comprehensive metrics DataFrame\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'Class': CLASS_NAMES,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'Support': support,\n",
        "        'ROC-AUC': [roc_auc.get(i, np.nan) for i in range(24)]\n",
        "    })\n",
        "    \n",
        "    # Save metrics\n",
        "    metrics_df.to_csv(os.path.join(output_dir, 'per_class_metrics.csv'), index=False)\n",
        "    \n",
        "    # Plot per-class metrics comparison\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
        "    \n",
        "    # Precision\n",
        "    axes[0, 0].bar(range(24), precision, color='steelblue', alpha=0.7)\n",
        "    axes[0, 0].set_xlabel('Chromosome Class', fontweight='bold')\n",
        "    axes[0, 0].set_ylabel('Precision', fontweight='bold')\n",
        "    axes[0, 0].set_title('Precision by Class', fontweight='bold', fontsize=14)\n",
        "    axes[0, 0].set_xticks(range(24))\n",
        "    axes[0, 0].set_xticklabels(CLASS_NAMES, rotation=45)\n",
        "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Recall\n",
        "    axes[0, 1].bar(range(24), recall, color='coral', alpha=0.7)\n",
        "    axes[0, 1].set_xlabel('Chromosome Class', fontweight='bold')\n",
        "    axes[0, 1].set_ylabel('Recall', fontweight='bold')\n",
        "    axes[0, 1].set_title('Recall by Class', fontweight='bold', fontsize=14)\n",
        "    axes[0, 1].set_xticks(range(24))\n",
        "    axes[0, 1].set_xticklabels(CLASS_NAMES, rotation=45)\n",
        "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # F1-Score\n",
        "    axes[1, 0].bar(range(24), f1, color='mediumseagreen', alpha=0.7)\n",
        "    axes[1, 0].set_xlabel('Chromosome Class', fontweight='bold')\n",
        "    axes[1, 0].set_ylabel('F1-Score', fontweight='bold')\n",
        "    axes[1, 0].set_title('F1-Score by Class', fontweight='bold', fontsize=14)\n",
        "    axes[1, 0].set_xticks(range(24))\n",
        "    axes[1, 0].set_xticklabels(CLASS_NAMES, rotation=45)\n",
        "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # ROC-AUC\n",
        "    roc_values = [roc_auc.get(i, 0) for i in range(24)]\n",
        "    axes[1, 1].bar(range(24), roc_values, color='mediumpurple', alpha=0.7)\n",
        "    axes[1, 1].set_xlabel('Chromosome Class', fontweight='bold')\n",
        "    axes[1, 1].set_ylabel('ROC-AUC', fontweight='bold')\n",
        "    axes[1, 1].set_title('ROC-AUC by Class', fontweight='bold', fontsize=14)\n",
        "    axes[1, 1].set_xticks(range(24))\n",
        "    axes[1, 1].set_xticklabels(CLASS_NAMES, rotation=45)\n",
        "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'per_class_metrics.png'),\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    print(\"✓ Per-class metrics saved\")\n",
        "    \n",
        "    # ==================== SUMMARY STATISTICS ====================\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"COMPUTING SUMMARY STATISTICS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Overall accuracy\n",
        "    overall_acc = accuracy_score(all_true_labels, all_pred_labels)\n",
        "    balanced_acc = balanced_accuracy_score(all_true_labels, all_pred_labels)\n",
        "    \n",
        "    # Weighted averages\n",
        "    weighted_precision = np.average(precision, weights=support)\n",
        "    weighted_recall = np.average(recall, weights=support)\n",
        "    weighted_f1 = np.average(f1, weights=support)\n",
        "    \n",
        "    # Macro averages\n",
        "    macro_precision = np.mean(precision)\n",
        "    macro_recall = np.mean(recall)\n",
        "    macro_f1 = np.mean(f1)\n",
        "    \n",
        "    summary = {\n",
        "        'Overall Accuracy': overall_acc,\n",
        "        'Balanced Accuracy': balanced_acc,\n",
        "        'Macro-avg Precision': macro_precision,\n",
        "        'Macro-avg Recall': macro_recall,\n",
        "        'Macro-avg F1-Score': macro_f1,\n",
        "        'Weighted-avg Precision': weighted_precision,\n",
        "        'Weighted-avg Recall': weighted_recall,\n",
        "        'Weighted-avg F1-Score': weighted_f1,\n",
        "        'Micro-avg ROC-AUC': roc_auc_micro,\n",
        "        'Macro-avg ROC-AUC': roc_auc_macro\n",
        "    }\n",
        "    \n",
        "    # Save summary\n",
        "    with open(os.path.join(output_dir, 'summary_statistics.txt'), 'w') as f:\n",
        "        f.write(\"=\"*80 + \"\\n\")\n",
        "        f.write(\"SUMMARY STATISTICS\\n\")\n",
        "        f.write(\"=\"*80 + \"\\n\\n\")\n",
        "        f.write(f\"Device Used: {DEVICE_TYPE}\\n\")\n",
        "        f.write(f\"Number of Replicas: {STRATEGY.num_replicas_in_sync}\\n\\n\")\n",
        "        for metric, value in summary.items():\n",
        "            f.write(f\"{metric:.<50} {value:.4f}\\n\")\n",
        "        f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUMMARY STATISTICS\")\n",
        "    print(\"=\"*60)\n",
        "    for metric, value in summary.items():\n",
        "        print(f\"{metric:.<50} {value:.4f}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    print(f\"\\n✓ All evaluation metrics saved to '{output_dir}/' directory\")\n",
        "    \n",
        "    return summary, metrics_df, cm\n",
        "\n",
        "# ==================== RUN EVALUATION ====================\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "summary_stats, per_class_metrics, conf_matrix = compute_comprehensive_metrics(\n",
        "    pipeline=pipeline,\n",
        "    images_dir=MULTI_CHR_IMAGES,\n",
        "    annotations_dir=MULTI_CHR_ANNOTATIONS,\n",
        "    test_list=test_list,\n",
        "    output_dir='evaluation_results'\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION METRICS GENERATION COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nDevice used: {DEVICE_TYPE}\")\n",
        "print(f\"Number of replicas: {STRATEGY.num_replicas_in_sync}\")\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  1. confusion_matrix.png - Raw confusion matrix\")\n",
        "print(\"  2. confusion_matrix_normalized.png - Normalized confusion matrix\")\n",
        "print(\"  3. roc_curves_all.png - Individual ROC curves for all classes\")\n",
        "print(\"  4. roc_curves_aggregate.png - Micro and macro-average ROC\")\n",
        "print(\"  5. classification_report.txt - Detailed classification report\")\n",
        "print(\"  6. classification_report.csv - Report in CSV format\")\n",
        "print(\"  7. per_class_metrics.csv - Per-class metrics table\")\n",
        "print(\"  8. per_class_metrics.png - Visual comparison of metrics\")\n",
        "print(\"  9. summary_statistics.txt - Overall performance summary\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aiml_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
