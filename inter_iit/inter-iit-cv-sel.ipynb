{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Configuration Guide\n",
    "\n",
    "### Configuration Flags (Set at the top of script)\n",
    "\n",
    "```python\n",
    "    TRAIN_IDENTIFIER: bool = True\n",
    "    TRAIN_CLASSIFIER: bool = True\n",
    "    RUN_EVALUATION: bool = True\n",
    "    VISUALIZE_PREDICTIONS: bool = True # Set to True to save example images\n",
    "    NUM_VISUALIZATION_IMAGES: int = 10 # Number of test images to visualize\n",
    "\n",
    "    # --- Model Paths ---\n",
    "    IDENTIFIER_MODEL_PATH: str = 'identifier_model.h5'\n",
    "    CLASSIFIER_MODEL_PATH: str = 'best_classifier.h5'\n",
    "    OUTPUT_DIR: str = 'pipeline_output' # Directory for plots and images\n",
    "\n",
    "    # --- Training Parameters ---\n",
    "    IDENTIFIER_EPOCHS: int = 5\n",
    "    CLASSIFIER_EPOCHS: int = 15\n",
    "    IDENTIFIER_IMG_SIZE: int = 800\n",
    "    CLASSIFIER_IMG_SIZE: int = 224\n",
    "    VALIDATION_SPLIT: float = 0.2\n",
    "\n",
    "    # --- Pipeline Parameters ---\n",
    "    DETECTION_THRESHOLD: float = 0.3      # Minimum confidence for a detected object\n",
    "    EVAL_IOU_THRESHOLD: float = 0.5       # IoU threshold to match pred/GT boxes\n",
    "\n",
    "    # --- Dataset Path ---\n",
    "    # Ensure this points to the correct directory\n",
    "    DATA_ROOT: str = '/kaggle/input/2025-karyogram-cv-camp/2025_Karyogram_CV_Camp'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-14T17:43:02.278662Z",
     "iopub.status.busy": "2025-10-14T17:43:02.277956Z",
     "iopub.status.idle": "2025-10-14T17:43:02.291188Z",
     "shell.execute_reply": "2025-10-14T17:43:02.290347Z",
     "shell.execute_reply.started": "2025-10-14T17:43:02.278633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#      ENHANCED CHROMOSOME DETECTION & CLASSIFICATION PIPELINE\n",
    "#\n",
    "# Key Improvements:\n",
    "# - Config Class: Centralized configuration for easier tuning.\n",
    "# - Memory-Efficient Generator: Classifier data generator loads images on-the-fly,\n",
    "#   drastically reducing RAM usage.\n",
    "# - Robust Evaluation: Uses IoU matching for a more accurate assessment of model\n",
    "#   performance on the test set.\n",
    "# - Added Visualizations:\n",
    "#   1. Training history plots (Accuracy/Loss).\n",
    "#   2. Detailed confusion matrix for classifier performance.\n",
    "#   3. Output images with predicted and ground-truth bounding boxes.\n",
    "#\n",
    "# Dependencies:\n",
    "# pip install tensorflow scikit-learn matplotlib seaborn pandas albumentations\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from itertools import cycle\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "# Suppress TensorFlow logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    balanced_accuracy_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "try:\n",
    "    import albumentations as A\n",
    "except ImportError:\n",
    "    print(\"Installing albumentations...\")\n",
    "    os.system('pip install -q albumentations')\n",
    "    import albumentations as A\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.config.optimizer.set_jit(False)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Holds all configuration parameters for the pipeline.\"\"\"\n",
    "    # --- Execution Control ---\n",
    "    TRAIN_IDENTIFIER: bool = True\n",
    "    TRAIN_CLASSIFIER: bool = True\n",
    "    RUN_EVALUATION: bool = True\n",
    "    VISUALIZE_PREDICTIONS: bool = True # Set to True to save example images\n",
    "    NUM_VISUALIZATION_IMAGES: int = 10 # Number of test images to visualize\n",
    "\n",
    "    # --- Model Paths ---\n",
    "    IDENTIFIER_MODEL_PATH: str = 'identifier_model.h5'\n",
    "    CLASSIFIER_MODEL_PATH: str = 'best_classifier.h5'\n",
    "    OUTPUT_DIR: str = 'pipeline_output' # Directory for plots and images\n",
    "\n",
    "    # --- Training Parameters ---\n",
    "    IDENTIFIER_EPOCHS: int = 5\n",
    "    CLASSIFIER_EPOCHS: int = 15\n",
    "    IDENTIFIER_IMG_SIZE: int = 800\n",
    "    CLASSIFIER_IMG_SIZE: int = 224\n",
    "    VALIDATION_SPLIT: float = 0.2\n",
    "\n",
    "    # --- Pipeline Parameters ---\n",
    "    DETECTION_THRESHOLD: float = 0.3      # Minimum confidence for a detected object\n",
    "    EVAL_IOU_THRESHOLD: float = 0.5       # IoU threshold to match pred/GT boxes\n",
    "\n",
    "    # --- Dataset Path ---\n",
    "    # Ensure this points to the correct directory\n",
    "    DATA_ROOT: str = '/kaggle/input/2025-karyogram-cv-camp/2025_Karyogram_CV_Camp'\n",
    "\n",
    "    # --- Class Mapping ---\n",
    "    CLASS_MAP: Dict[str, int] = {\n",
    "        '1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5,\n",
    "        '7': 6, '8': 7, '9': 8, '10': 9, '11': 10, '12': 11,\n",
    "        '13': 12, '14': 13, '15': 14, '16': 15, '17': 16, '18': 17,\n",
    "        '19': 18, '20': 19, '21': 20, '22': 21, 'X': 22, 'Y': 23\n",
    "    }\n",
    "    CLASS_NAMES: List[str] = [name for name, _ in sorted(CLASS_MAP.items(), key=lambda item: item[1])]\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. DEVICE SETUP\n",
    "# ==============================================================================\n",
    "\n",
    "def setup_device_strategy() -> Tuple[tf.distribute.Strategy, str]:\n",
    "    \"\"\"Detects and initializes the appropriate hardware (TPU, GPU, CPU).\"\"\"\n",
    "    print(\"=\"*60 + \"\\nINITIALIZING DEVICE\\n\" + \"=\"*60)\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "        strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        device_type = \"TPU\"\n",
    "        print(f\"âœ… TPU detected and initialized with {strategy.num_replicas_in_sync} cores.\")\n",
    "        return strategy, device_type\n",
    "    except (ValueError, tf.errors.NotFoundError):\n",
    "        print(\"INFO: No TPU detected.\")\n",
    "\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        if len(gpus) > 1:\n",
    "            strategy = tf.distribute.MirroredStrategy()\n",
    "            device_type = \"Multi-GPU\"\n",
    "            print(f\"âœ… Multi-GPU detected with {strategy.num_replicas_in_sync} devices.\")\n",
    "        else:\n",
    "            strategy = tf.distribute.get_strategy()\n",
    "            device_type = \"Single-GPU\"\n",
    "            print(\"âœ… Single GPU detected.\")\n",
    "        return strategy, device_type\n",
    "\n",
    "    print(\"âœ… No GPU or TPU detected. Falling back to CPU.\")\n",
    "    return tf.distribute.get_strategy(), \"CPU\"\n",
    "\n",
    "STRATEGY, DEVICE_TYPE = setup_device_strategy()\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. UTILITIES & VISUALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "class AnnotationParser:\n",
    "    \"\"\"Parses XML annotation files.\"\"\"\n",
    "    @staticmethod\n",
    "    def parse_xml(xml_path: Path) -> Dict[str, Any]:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        annotations = {'objects': []}\n",
    "        for obj in root.findall('object'):\n",
    "            bndbox = obj.find('bndbox')\n",
    "            if bndbox is not None:\n",
    "                annotations['objects'].append({\n",
    "                    'name': obj.find('name').text,\n",
    "                    'bbox': [\n",
    "                        int(float(bndbox.find('xmin').text)),\n",
    "                        int(float(bndbox.find('ymin').text)),\n",
    "                        int(float(bndbox.find('xmax').text)),\n",
    "                        int(float(bndbox.find('ymax').text))\n",
    "                    ]\n",
    "                })\n",
    "        return annotations\n",
    "\n",
    "def compute_iou(boxA: List[int], boxB: List[int]) -> float:\n",
    "    \"\"\"Calculates Intersection over Union (IoU) between two bounding boxes.\"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    inter_area = max(0, xB - xA) * max(0, yB - yA)\n",
    "    boxA_area = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxB_area = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    union_area = float(boxA_area + boxB_area - inter_area)\n",
    "    return inter_area / union_area if union_area > 0 else 0.0\n",
    "\n",
    "def plot_training_history(history: keras.callbacks.History, save_path: Path):\n",
    "    \"\"\"Plots and saves the training/validation accuracy and loss curves.\"\"\"\n",
    "    pd.DataFrame(history.history).plot(figsize=(12, 8))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.title(\"Classifier Training History\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"âœ… Training history saved to '{save_path}'\")\n",
    "\n",
    "def plot_confusion_matrix(y_true: List, y_pred: List, class_names: List, save_path: Path):\n",
    "    \"\"\"Plots and saves a confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(18, 15))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"âœ… Confusion matrix saved to '{save_path}'\")\n",
    "\n",
    "def visualize_predictions(image_path: Path, gt_boxes: List, predictions: List, save_path: Path, iou_thresh: float):\n",
    "    \"\"\"Draws ground truth and predicted boxes on an image and saves it.\"\"\"\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 15))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Draw Ground Truth Boxes (Green)\n",
    "    for gt in gt_boxes:\n",
    "        xmin, ymin, xmax, ymax = gt['bbox']\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='g', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(xmin, ymin - 10, f\"GT: {gt['name']}\", color='g', fontsize=12, weight='bold')\n",
    "\n",
    "    # Draw Predicted Boxes (Red)\n",
    "    for pred in predictions:\n",
    "        xmin, ymin, xmax, ymax = map(int, pred['bbox'])\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        label = f\"Pred: {pred['class_name']} ({pred['combined_score']:.2f})\"\n",
    "        ax.text(xmin, ymax + 20, label, color='r', fontsize=12, weight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. IDENTIFIER MODULE (Chromosome Detector)\n",
    "# ==============================================================================\n",
    "\n",
    "class ChromosomeIdentifierDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Generates batches of data for the identifier model.\"\"\"\n",
    "    def __init__(self, images_dir: Path, annotations_dir: Path, batch_size: int, img_size: int, shuffle: bool = True):\n",
    "        self.images_dir = images_dir\n",
    "        self.annotations_dir = annotations_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.parser = AnnotationParser()\n",
    "        self.image_list = sorted([p.stem for p in self.images_dir.glob('*.jpg')] + [p.stem for p in self.images_dir.glob('*.png')])\n",
    "        self.indexes = np.arange(len(self.image_list))\n",
    "        self.on_epoch_end()\n",
    "        print(f\"IdentifierDataGenerator: Found {len(self.image_list)} images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_list) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_images = [self.image_list[k] for k in batch_indexes]\n",
    "        images, targets = self._generate_data(batch_images)\n",
    "        return np.array(images), targets\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle: np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _generate_data(self, batch_images):\n",
    "        images, targets = [], []\n",
    "        for img_name in batch_images:\n",
    "            img_path = self.images_dir / f\"{img_name}.jpg\"\n",
    "            if not img_path.exists(): img_path = self.images_dir / f\"{img_name}.png\"\n",
    "            xml_path = self.annotations_dir / f\"{img_name}.xml\"\n",
    "\n",
    "            if not img_path.exists() or not xml_path.exists(): continue\n",
    "\n",
    "            image = cv2.imread(str(img_path))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            orig_h, orig_w = image.shape[:2]\n",
    "\n",
    "            image_resized = cv2.resize(image, (self.img_size, self.img_size))\n",
    "            image_resized = image_resized.astype(np.float32) / 255.0\n",
    "\n",
    "            annotations = self.parser.parse_xml(xml_path)\n",
    "            boxes = []\n",
    "            for obj in annotations['objects']:\n",
    "                bbox = obj['bbox']\n",
    "                boxes.append([bbox[1]/orig_h, bbox[0]/orig_w, bbox[3]/orig_h, bbox[2]/orig_w]) # ymin, xmin, ymax, xmax\n",
    "\n",
    "            images.append(image_resized)\n",
    "            targets.append(np.array(boxes) if boxes else np.zeros((0, 4)))\n",
    "\n",
    "        return images, targets\n",
    "\n",
    "\n",
    "class ChromosomeIdentifier:\n",
    "    \"\"\"The chromosome detection model (based on ResNet50).\"\"\"\n",
    "    def __init__(self, img_size: int = 800, max_detections: int = 50):\n",
    "        self.img_size = img_size\n",
    "        self.max_detections = max_detections\n",
    "        self.model = None\n",
    "\n",
    "    def _build_model(self):\n",
    "        inputs = layers.Input(shape=(self.img_size, self.img_size, 3))\n",
    "        base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "        for layer in base_model.layers[:100]: layer.trainable = False\n",
    "        x = base_model.output\n",
    "        x = layers.Conv2D(512, 3, padding='same', activation='relu')(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(1024, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        bbox_output = layers.Dense(self.max_detections * 4, name='bbox')(x)\n",
    "        objectness = layers.Dense(self.max_detections, activation='sigmoid', name='objectness')(x)\n",
    "        return models.Model(inputs=inputs, outputs=[bbox_output, objectness])\n",
    "\n",
    "    def train(self, train_gen: ChromosomeIdentifierDataGenerator, epochs: int, strategy: tf.distribute.Strategy):\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\nðŸš€ STARTING IDENTIFIER TRAINING\\n\" + \"=\"*60)\n",
    "        with strategy.scope():\n",
    "            self.model = self._build_model()\n",
    "            optimizer = optimizers.Adam(0.001)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "            epoch_losses = []\n",
    "            for batch_idx in range(len(train_gen)):\n",
    "                images, targets = train_gen[batch_idx]\n",
    "                if images.size == 0: continue\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    bbox_pred, obj_pred = self.model(images, training=True)\n",
    "                    bbox_pred = tf.reshape(bbox_pred, (-1, self.max_detections, 4))\n",
    "\n",
    "                    batch_loss = 0\n",
    "                    for i, target_boxes in enumerate(targets):\n",
    "                        num_objs = min(len(target_boxes), self.max_detections)\n",
    "                        if num_objs > 0:\n",
    "                            target_padded = np.zeros((self.max_detections, 4))\n",
    "                            target_padded[:num_objs] = target_boxes[:num_objs]\n",
    "                            bbox_loss = tf.reduce_mean(tf.square(bbox_pred[i] - target_padded))\n",
    "                            obj_target = np.zeros(self.max_detections)\n",
    "                            obj_target[:num_objs] = 1\n",
    "                            obj_loss = tf.keras.losses.binary_crossentropy(obj_target, obj_pred[i])\n",
    "                            batch_loss += bbox_loss + 0.5 * tf.reduce_mean(obj_loss)\n",
    "                    batch_loss /= len(targets)\n",
    "\n",
    "                grads = tape.gradient(batch_loss, self.model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "                epoch_losses.append(float(batch_loss))\n",
    "                if (batch_idx + 1) % 10 == 0:\n",
    "                    print(f\"  Batch {batch_idx+1}/{len(train_gen)}, Loss: {np.mean(epoch_losses[-10:]):.4f}\")\n",
    "            print(f\"Epoch {epoch+1} Average Loss: {np.mean(epoch_losses):.4f}\")\n",
    "        print(\"\\nâœ… Identifier training complete.\")\n",
    "        return self.model\n",
    "\n",
    "    def predict_boxes(self, image: np.ndarray, confidence_threshold: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        orig_h, orig_w = image.shape[:2]\n",
    "        image_resized = cv2.resize(image, (self.img_size, self.img_size))\n",
    "        image_resized = np.expand_dims(image_resized.astype(np.float32) / 255.0, axis=0)\n",
    "        bbox_pred, obj_pred = self.model.predict(image_resized, verbose=0)\n",
    "        bbox_pred = bbox_pred.reshape(self.max_detections, 4)\n",
    "        obj_pred = obj_pred.flatten()\n",
    "\n",
    "        keep_indices = obj_pred > confidence_threshold\n",
    "        boxes = bbox_pred[keep_indices]\n",
    "        scores = obj_pred[keep_indices]\n",
    "\n",
    "        final_boxes = []\n",
    "        for ymin, xmin, ymax, xmax in boxes:\n",
    "            final_boxes.append([\n",
    "                max(0, int(xmin * orig_w)), max(0, int(ymin * orig_h)),\n",
    "                min(orig_w, int(xmax * orig_w)), min(orig_h, int(ymax * orig_h))\n",
    "            ])\n",
    "        return np.array(final_boxes), scores\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. CLASSIFIER MODULE (Chromosome Type Classifier)\n",
    "# ==============================================================================\n",
    "class ChromosomeClassifierDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Memory-efficient data generator for the classifier.\n",
    "    Loads and crops images on-the-fly instead of storing them in memory.\n",
    "    \"\"\"\n",
    "    def __init__(self, images_dir: Path, annotations_dir: Path, batch_size: int, img_size: int,\n",
    "                 class_map: Dict, is_validation: bool = False, augment: bool = False,\n",
    "                 validation_split: float = 0.2, data_list=None, indexes=None):\n",
    "        self.images_dir, self.annotations_dir = images_dir, annotations_dir\n",
    "        self.batch_size, self.img_size = batch_size, img_size\n",
    "        self.class_map, self.is_validation = class_map, is_validation\n",
    "\n",
    "        if data_list is None or indexes is None:\n",
    "            self.chromosome_data = self._build_dataset_index()\n",
    "            all_indexes = np.arange(len(self.chromosome_data))\n",
    "            np.random.seed(42)\n",
    "            np.random.shuffle(all_indexes)\n",
    "            val_size = int(len(self.chromosome_data) * validation_split)\n",
    "            self.val_indexes = all_indexes[:val_size]\n",
    "            self.train_indexes = all_indexes[val_size:]\n",
    "            self.indexes = self.val_indexes if self.is_validation else self.train_indexes\n",
    "        else:\n",
    "            self.chromosome_data = data_list\n",
    "            self.indexes = indexes\n",
    "\n",
    "        self.aug = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5), A.Rotate(limit=20, p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.3), A.GaussNoise(p=0.2),\n",
    "        ]) if augment and not self.is_validation else None\n",
    "\n",
    "    def _build_dataset_index(self) -> List[Dict]:\n",
    "        \"\"\"Builds an index of chromosome locations, not the images themselves.\"\"\"\n",
    "        print(\"\\nBuilding classifier dataset index...\")\n",
    "        index = []\n",
    "        image_files = sorted([p.stem for p in self.images_dir.glob('*.jpg')] + [p.stem for p in self.images_dir.glob('*.png')])\n",
    "        for img_name in image_files:\n",
    "            xml_path = self.annotations_dir / f\"{img_name}.xml\"\n",
    "            if not xml_path.exists(): continue\n",
    "            try:\n",
    "                annotations = AnnotationParser.parse_xml(xml_path)\n",
    "                for obj in annotations['objects']:\n",
    "                    if obj['name'] in self.class_map:\n",
    "                        index.append({\n",
    "                            'img_name': img_name,\n",
    "                            'bbox': obj['bbox'],\n",
    "                            'label': self.class_map[obj['name']]\n",
    "                        })\n",
    "            except Exception:\n",
    "                continue\n",
    "        print(f\"âœ… Found {len(index)} chromosome samples across {len(image_files)} images.\")\n",
    "        return index\n",
    "\n",
    "    def get_validation_generator(self):\n",
    "        \"\"\"Creates a generator for the validation set.\"\"\"\n",
    "        return ChromosomeClassifierDataGenerator(\n",
    "            self.images_dir, self.annotations_dir, self.batch_size, self.img_size,\n",
    "            self.class_map, is_validation=True, augment=False,\n",
    "            data_list=self.chromosome_data, indexes=self.val_indexes\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indexes) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_images, batch_labels = [], []\n",
    "\n",
    "        for idx in batch_indexes:\n",
    "            item = self.chromosome_data[idx]\n",
    "            img_path = self.images_dir / f\"{item['img_name']}.jpg\"\n",
    "            if not img_path.exists(): img_path = self.images_dir / f\"{item['img_name']}.png\"\n",
    "\n",
    "            try:\n",
    "                image = cv2.imread(str(img_path))\n",
    "                xmin, ymin, xmax, ymax = item['bbox']\n",
    "                crop = image[ymin:ymax, xmin:xmax]\n",
    "                if crop.size == 0: continue\n",
    "\n",
    "                if self.aug: crop = self.aug(image=crop)['image']\n",
    "\n",
    "                resized_crop = cv2.resize(crop, (self.img_size, self.img_size))\n",
    "                normalized_crop = (resized_crop.astype(np.float32) / 255.0 - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "\n",
    "                batch_images.append(normalized_crop)\n",
    "                batch_labels.append(item['label'])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if not batch_images: # Handle empty batches\n",
    "            return np.zeros((self.batch_size, self.img_size, self.img_size, 3), dtype=np.float32), \\\n",
    "                   np.zeros(self.batch_size, dtype=np.int32)\n",
    "        return np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "class ChromosomeClassifier:\n",
    "    \"\"\"The chromosome classification model (based on ResNet50).\"\"\"\n",
    "    def __init__(self, num_classes: int, img_size: int):\n",
    "        self.num_classes = num_classes\n",
    "        self.img_size = img_size\n",
    "        self.model = None\n",
    "\n",
    "    def _build_model(self):\n",
    "        base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(self.img_size, self.img_size, 3))\n",
    "        for layer in base_model.layers[:140]: layer.trainable = False\n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "        return models.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "    def compile_model(self, lr: float, strategy: tf.distribute.Strategy):\n",
    "        with strategy.scope():\n",
    "            self.model = self._build_model()\n",
    "            self.model.compile(optimizer=optimizers.Adam(lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def train(self, train_gen, val_gen, epochs: int, model_save_path: str):\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\nðŸš€ STARTING CLASSIFIER TRAINING\\n\" + \"=\"*60)\n",
    "        callbacks = [\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-7, verbose=1),\n",
    "            keras.callbacks.ModelCheckpoint(model_save_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "            keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=1)\n",
    "        ]\n",
    "        history = self.model.fit(train_gen, validation_data=val_gen, epochs=epochs, callbacks=callbacks, verbose=1)\n",
    "        print(\"\\nâœ… Classifier training complete.\")\n",
    "        return history\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. END-TO-END PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "class KaryotypePipeline:\n",
    "    \"\"\"Orchestrates the detection and classification process.\"\"\"\n",
    "    def __init__(self, identifier: ChromosomeIdentifier, classifier: ChromosomeClassifier, detection_threshold: float):\n",
    "        self.identifier = identifier\n",
    "        self.classifier = classifier\n",
    "        self.detection_threshold = detection_threshold\n",
    "        self.classifier_img_size = classifier.img_size\n",
    "\n",
    "    def process_image(self, image_path: Path) -> List[Dict]:\n",
    "        image = cv2.imread(str(image_path))\n",
    "        if image is None: return []\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        boxes, scores = self.identifier.predict_boxes(image_rgb, self.detection_threshold)\n",
    "        if len(boxes) == 0: return []\n",
    "\n",
    "        predictions = []\n",
    "        for i, box in enumerate(boxes):\n",
    "            xmin, ymin, xmax, ymax = map(int, box)\n",
    "            if xmax <= xmin or ymax <= ymin: continue\n",
    "\n",
    "            crop = image_rgb[ymin:ymax, xmin:xmax]\n",
    "            if crop.size == 0: continue\n",
    "\n",
    "            resized_crop = cv2.resize(crop, (self.classifier_img_size, self.classifier_img_size))\n",
    "            normalized_crop = (resized_crop.astype(np.float32)/255.0 - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "            normalized_crop = np.expand_dims(normalized_crop, axis=0)\n",
    "\n",
    "            probs = self.classifier.model.predict(normalized_crop, verbose=0)[0]\n",
    "            class_id = np.argmax(probs)\n",
    "            confidence = probs[class_id]\n",
    "            combined_score = float(scores[i]) * confidence\n",
    "\n",
    "            predictions.append({\n",
    "                'bbox': box.tolist(), 'class_id': int(class_id), 'confidence': float(confidence),\n",
    "                'class_name': self._get_class_name(class_id), 'combined_score': combined_score\n",
    "            })\n",
    "        return predictions\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_class_name(class_id: int) -> str:\n",
    "        return Config.CLASS_NAMES[class_id]\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. MAIN EXECUTION SCRIPT\n",
    "# ==============================================================================\n",
    "def main():\n",
    "    \"\"\"Main function to run the entire pipeline.\"\"\"\n",
    "    # Setup paths and output directory\n",
    "    output_dir = Path(Config.OUTPUT_DIR)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    data_root = Path(Config.DATA_ROOT)\n",
    "    single_chr_images = data_root / 'single_chromosomes_object' / 'images'\n",
    "    single_chr_annotations = data_root / 'single_chromosomes_object' / 'annotations'\n",
    "    multi_chr_images = data_root / '24_chromosomes_object' / 'images'\n",
    "    multi_chr_annotations = data_root / '24_chromosomes_object' / 'annotations'\n",
    "\n",
    "    # Dynamic batch sizes based on device\n",
    "    if DEVICE_TYPE == \"TPU\":\n",
    "        id_batch, cls_batch = 8 * STRATEGY.num_replicas_in_sync, 128 * STRATEGY.num_replicas_in_sync\n",
    "    else: # GPU or CPU\n",
    "        id_batch, cls_batch = 4 * STRATEGY.num_replicas_in_sync, 64 * STRATEGY.num_replicas_in_sync\n",
    "    print(f\"\\nUsing Batch Sizes -> Identifier: {id_batch}, Classifier: {cls_batch}\\n\")\n",
    "\n",
    "    # --- Step 1: Train or Load Identifier ---\n",
    "    identifier = ChromosomeIdentifier(img_size=Config.IDENTIFIER_IMG_SIZE)\n",
    "    if Config.TRAIN_IDENTIFIER:\n",
    "        id_gen = ChromosomeIdentifierDataGenerator(single_chr_images, single_chr_annotations, id_batch, Config.IDENTIFIER_IMG_SIZE)\n",
    "        identifier.train(id_gen, Config.IDENTIFIER_EPOCHS, STRATEGY)\n",
    "        identifier.model.save(Config.IDENTIFIER_MODEL_PATH)\n",
    "        print(f\"âœ… Identifier model saved to '{Config.IDENTIFIER_MODEL_PATH}'\")\n",
    "    else:\n",
    "        print(f\"ðŸ”„ Loading pre-trained identifier from '{Config.IDENTIFIER_MODEL_PATH}'...\")\n",
    "        identifier.model = keras.models.load_model(Config.IDENTIFIER_MODEL_PATH)\n",
    "\n",
    "    # --- Step 2: Train or Load Classifier ---\n",
    "    classifier = ChromosomeClassifier(num_classes=len(Config.CLASS_NAMES), img_size=Config.CLASSIFIER_IMG_SIZE)\n",
    "    if Config.TRAIN_CLASSIFIER:\n",
    "        train_cls_gen = ChromosomeClassifierDataGenerator(\n",
    "            multi_chr_images, multi_chr_annotations, cls_batch, Config.CLASSIFIER_IMG_SIZE,\n",
    "            Config.CLASS_MAP, augment=True, validation_split=Config.VALIDATION_SPLIT\n",
    "        )\n",
    "        val_cls_gen = train_cls_gen.get_validation_generator()\n",
    "        classifier.compile_model(lr=0.001, strategy=STRATEGY)\n",
    "        history = classifier.train(train_cls_gen, val_cls_gen, Config.CLASSIFIER_EPOCHS, Config.CLASSIFIER_MODEL_PATH)\n",
    "        plot_training_history(history, output_dir / 'classifier_training_history.png')\n",
    "    else:\n",
    "        print(f\"ðŸ”„ Loading pre-trained classifier from '{Config.CLASSIFIER_MODEL_PATH}'...\")\n",
    "        classifier.model = keras.models.load_model(Config.CLASSIFIER_MODEL_PATH)\n",
    "\n",
    "    # --- Step 3: Run Evaluation and Visualization ---\n",
    "    if Config.RUN_EVALUATION:\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\nðŸ“Š RUNNING EVALUATION\\n\" + \"=\"*60)\n",
    "        test_file = data_root / 'test.txt'\n",
    "        if not test_file.exists():\n",
    "            print(f\"âš ï¸ Warning: test.txt not found. Skipping evaluation.\")\n",
    "            return\n",
    "\n",
    "        with open(test_file, 'r') as f:\n",
    "            test_list = [line.strip() for line in f.readlines()]\n",
    "        print(f\"Found {len(test_list)} test samples.\")\n",
    "\n",
    "        pipeline = KaryotypePipeline(identifier, classifier, Config.DETECTION_THRESHOLD)\n",
    "        parser = AnnotationParser()\n",
    "        y_true, y_pred = [], []\n",
    "        \n",
    "        # Create a directory for visualization images\n",
    "        vis_dir = output_dir / 'visualizations'\n",
    "        if Config.VISUALIZE_PREDICTIONS:\n",
    "            vis_dir.mkdir(exist_ok=True)\n",
    "            print(f\"Visualizations will be saved to '{vis_dir}'\")\n",
    "\n",
    "        for i, img_name in enumerate(test_list):\n",
    "            print(f\"Processing image {i+1}/{len(test_list)}: {img_name}\")\n",
    "            img_path = multi_chr_images / f\"{img_name}.jpg\"\n",
    "            if not img_path.exists(): img_path = multi_chr_images / f\"{img_name}.png\"\n",
    "            xml_path = multi_chr_annotations / f\"{img_name}.xml\"\n",
    "            if not img_path.exists() or not xml_path.exists(): continue\n",
    "\n",
    "            gt_annotations = parser.parse_xml(xml_path)\n",
    "            predictions = pipeline.process_image(img_path)\n",
    "\n",
    "            gt_boxes = [obj for obj in gt_annotations['objects'] if obj['name'] in Config.CLASS_MAP]\n",
    "            \n",
    "            # Match predictions to ground truth\n",
    "            for gt_box_info in gt_boxes:\n",
    "                gt_bbox = gt_box_info['bbox']\n",
    "                gt_label = Config.CLASS_MAP[gt_box_info['name']]\n",
    "                best_iou, best_pred_label = -1, -1\n",
    "\n",
    "                for pred in predictions:\n",
    "                    iou = compute_iou(gt_bbox, pred['bbox'])\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_pred_label = pred['class_id']\n",
    "                \n",
    "                if best_iou >= Config.EVAL_IOU_THRESHOLD:\n",
    "                    y_true.append(gt_label)\n",
    "                    y_pred.append(best_pred_label)\n",
    "                else: # Missed detection\n",
    "                    y_true.append(gt_label)\n",
    "                    y_pred.append(-1) # Special class for missed detections\n",
    "\n",
    "            # Visualize some predictions\n",
    "            if Config.VISUALIZE_PREDICTIONS and i < Config.NUM_VISUALIZATION_IMAGES:\n",
    "                vis_save_path = vis_dir / f\"{img_name}_pred.png\"\n",
    "                visualize_predictions(img_path, gt_boxes, predictions, vis_save_path, Config.EVAL_IOU_THRESHOLD)\n",
    "        \n",
    "        # Filter out missed detections for classification metrics\n",
    "        y_true_cls = [yt for i, yt in enumerate(y_true) if y_pred[i] != -1]\n",
    "        y_pred_cls = [yp for yp in y_pred if yp != -1]\n",
    "\n",
    "        # --- Display Results ---\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\nEVALUATION RESULTS\\n\" + \"=\"*60)\n",
    "        if y_true_cls:\n",
    "            report = classification_report(y_true_cls, y_pred_cls, target_names=Config.CLASS_NAMES, zero_division=0)\n",
    "            print(\"Classification Report (on matched boxes):\")\n",
    "            print(report)\n",
    "            plot_confusion_matrix(y_true_cls, y_pred_cls, Config.CLASS_NAMES, output_dir / 'confusion_matrix.png')\n",
    "            \n",
    "            acc = accuracy_score(y_true_cls, y_pred_cls)\n",
    "            bal_acc = balanced_accuracy_score(y_true_cls, y_pred_cls)\n",
    "            print(f\"\\nOverall Accuracy (matched): {acc:.4f}\")\n",
    "            print(f\"Balanced Accuracy (matched): {bal_acc:.4f}\")\n",
    "        else:\n",
    "            print(\"No valid matched boxes found for classification report.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8486113,
     "sourceId": 13375782,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
