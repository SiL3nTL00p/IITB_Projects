{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def load_and_chunk_pdf(path):\n",
    "    reader = PdfReader(path)\n",
    "    raw_text = \"\"\n",
    "\n",
    "    for page in reader.pages:\n",
    "        if page.extract_text():\n",
    "            raw_text += page.extract_text()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_text(raw_text)\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def create_faiss_index(chunks):\n",
    "    docs = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    return db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(query, db, k=15):\n",
    "    results = db.similarity_search(query, k=k)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code loads the main LLM whih is Groq in this case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import requests,os\n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "GROQ_API_KEY = \"i removed mine for security reasons, please set your own\"  \n",
    "\n",
    "def generate_answer_groq(query, context, model=\"llama3-8b-8192\"):\n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    system_prompt = \"You are a helpful assistant that answers questions based only on the provided context.\"\n",
    "    user_prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "    try:\n",
    "        data = response.json()\n",
    "        if \"choices\" in data:\n",
    "            return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            return f\"⚠️ Unexpected response: {data}\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error: {e} | Raw response: {response.text}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chatbot(query, db):\n",
    "    docs = retrieve_docs(query, db)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    answer = generate_answer_groq(query, context)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/pmanthan/Desktop/AICommunity_Assignment_25.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_chunk_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/pmanthan/Desktop/AICommunity_Assignment_25.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m db \u001b[38;5;241m=\u001b[39m create_faiss_index(chunks)\n\u001b[1;32m      4\u001b[0m response \u001b[38;5;241m=\u001b[39m rag_chatbot(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is the second technical question in detail\u001b[39m\u001b[38;5;124m\"\u001b[39m,db)\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mload_and_chunk_pdf\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_and_chunk_pdf\u001b[39m(path):\n\u001b[0;32m----> 5\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     raw_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mpages:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml_env/lib/python3.10/site-packages/PyPDF2/_reader.py:317\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    311\u001b[0m     logger_warning(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPdfReader stream/file object is not in binary mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt may not be read correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    315\u001b[0m     )\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    318\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(stream)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/pmanthan/Desktop/AICommunity_Assignment_25.pdf'"
     ]
    }
   ],
   "source": [
    "chunks = load_and_chunk_pdf(\"/Users/pmanthan/Desktop/AICommunity_Assignment_25.pdf\")\n",
    "db = create_faiss_index(chunks)\n",
    "\n",
    "response = rag_chatbot(\"what is the second technical question in detail\",db)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
